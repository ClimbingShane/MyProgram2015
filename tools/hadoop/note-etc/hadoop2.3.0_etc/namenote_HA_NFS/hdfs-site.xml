<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<!--
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License. See accompanying LICENSE file.
-->

<!-- Put site-specific property overrides in this file. -->

<configuration>


<property>
    <name>dfs.nameservices</name>
    <value>ns1</value>
</property>

<property>
    <name>dfs.ha.namenodes.ns1</name>
    <value>nn1,nn2</value>
</property>

<property>
    <name>dfs.namenode.rpc-address.ns1.nn1</name>
    <value>centos1:9000</value>
</property>

<property>
    <name>dfs.namenode.http-address.ns1.nn1</name>
    <value>centos1:50070</value>
</property>

<property>
    <name>dfs.namenode.rpc-address.ns1.nn2</name>
    <value>centos2:9000</value>
</property>

<property>
    <name>dfs.namenode.http-address.ns1.nn2</name>
    <value>centos2:50070</value>
</property>

<!--nfs share-->
<property>
    <name>dfs.namenode.shared.edits.dir</name>
    <value>file:///nfs/ha-edits</value>
</property>

<property>
    <name>ha.zookeeper.quorum</name>
    <value>centos1:2181,centos2:2181,centos3:2181,</value>
</property>

<property>
    <name>ha.zookeeper.session-timeout.ms</name>
    <value>10000</value>
</property>

<property>
    <name>dfs.ha.fencing.methods</name>
    <value>sshfence</value>
</property>

<property>
    <name>dfs.ha.automatic-failover.enabled</name>
    <value>true</value>
</property>

<property>
    <name>dfs.client.failover.proxy.provider.ns1</name>
    <value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
</property>

<!--ssh config-->
<property>
    <name>dfs.permissions.superusergroup</name>
    <value>hadoop</value>
</property>

<property>
 	<name>dfs.ha.fencing.ssh.private-key-files</name>
	<value>/home/hadoop/.ssh/id_rsa</value>
</property>

<property>
 	<name>dfs.ha.fencing.ssh.connect-timeout</name>
 	<value>5000</value>
</property>


<property>
	<name>hadoop.hdfs.configuration.version</name>
	<value>1</value>
	<description>version of this configuration file</description>
</property>

<property>
	<name>dfs.namenode.logging.level</name>
	<value>info</value>
	<description>
	The logging level for dfs namenode. Other values are "dir" (trace
	namespace mutations), "block" (trace block under/over replications
	and block creations/deletions), or "all".
	</description>
</property>

<property>
	<name>dfs.namenode.name.dir</name>
	<value>file:///hadoop/dfsdata/name</value>
	  <description>Determines where on the local filesystem the DFS name node
      should store the name table(fsimage).  If this is a comma-delimited list
      of directories then the name table is replicated in all of the
      directories, for redundancy.
  	</description>
</property>

 

<property> 
 	<name>dfs.datanode.data.dir</name>
 	<value>file:///hadoop/dfsdata/data</value>
	<description>Determines where on the local filesystem an DFS data node
	should store its blocks.  If this is a comma-delimited
	list of directories, then data will be stored in all named
	directories, typically on different devices.
	Directories that do not exist are ignored.
	</description>
</property>

<property>
  	<name>dfs.namenode.secondary.http-address</name>
  	<value>0.0.0.0:50090</value>
  	<description>
    The secondary namenode http server address and port.
    If the port is 0 then the server will start on a free port.
  	</description>
</property>

<property>
	<name>dfs.datanode.address</name>
	<value>0.0.0.0:50010</value>
	<description>
	The datanode server address and port for data transfer.
	If the port is 0 then the server will start on a free port.
	</description>
</property>

<property>
	<name>dfs.datanode.http.address</name>
	<value>0.0.0.0:50075</value>
	<description>
	The datanode http server address and port.
	If the port is 0 then the server will start on a free port.
	</description>
</property>

<property>
	<name>dfs.datanode.ipc.address</name>
	<value>0.0.0.0:50020</value>
	<description>
	The datanode ipc server address and port.
	If the port is 0 then the server will start on a free port.
	</description>
</property>

<property>
 	<name>dfs.replication</name>
 	<value>2</value>
</property>

<property> 
 	<name>dfs.permission</name>
 	<value>false</value>
</property>

</configuration>
